{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import numpy as np\n",
    "dt=[]\n",
    "lb=[]\n",
    "def load_review_dataset():\n",
    "    i=0\n",
    "    neg_path = 'neg'\n",
    "    pos_path = 'pos'\n",
    "    dataset=[]\n",
    "    labels=[]\n",
    "    for f_path in [neg_path,pos_path]:\n",
    "        for txt_pth in [os.path.join(f_path,p) for p in os.listdir(f_path)]:\n",
    "            with open(txt_pth,'r',encoding=\"utf-8\") as txt_file:\n",
    "                txt = txt_file.read()\n",
    "                dataset.append(txt)\n",
    "#                 print(f_path)\n",
    "                labels.append(f_path)\n",
    "                i=i+1\n",
    "#     labels = np.full((50000), 0); y[100:200] = 1\n",
    "    return dataset,labels,i\n",
    "# load_review_dataset()\n",
    "dt,lb,a=load_review_dataset()\n",
    "print(len(dt))\n",
    "print('finish')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "50000\n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "lemmatizer = WordNetLemmatizer() \n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "def preproc(dt):\n",
    "    print(len(dt))\n",
    "    dtt = []\n",
    "    labelsTest = []\n",
    "    for i in range(len(dt)):    \n",
    "        tokens1 = word_tokenize(dt[i])\n",
    "    #     tokenisasi -> memecah setiap kalimat menjadi kata\n",
    "    #     print(\"Tokenize\")\n",
    "    #     print(tokens1)\n",
    "    #     mengubah menjadi lowercase\n",
    "        normalized_words1 = [w.lower() for w in tokens1]\n",
    "    #     print(\"lower\")\n",
    "    #     print(normalized_words1)\n",
    "    #     mengubah tanda baca menjadi string kosong\n",
    "        table = str.maketrans('', '', string.punctuation)\n",
    "        punc_removed1 = [w.translate(table) for w in normalized_words1]\n",
    "    #     print(\"punc_removed1:\\n\", punc_removed1)\n",
    "    #     mengambil token-token yang berupa huruf alpabet\n",
    "        isalpha_words1 = [word for word in punc_removed1 if word.isalpha()]\n",
    "    #     print(\"isalpha_words1:\\n\", isalpha_words1)\n",
    "    #     menghilangkan stop words bahasa inggris\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        stopWords_removed1 = [w for w in isalpha_words1 if not w in stop_words]\n",
    "    #     print(\"stopWords_removed1:\\n\", stopWords_removed1)\n",
    "    #     mencari kata dasar\n",
    "        lemmatized_words1 = [lemmatizer.lemmatize(w) for w in stopWords_removed1]\n",
    "    #     print(\"lemmatized_words1:\\n\", lemmatized_words1)\n",
    "    #     untokenize\n",
    "        dt[i] = TreebankWordDetokenizer().detokenize(lemmatized_words1)\n",
    "        dtt.append(dt[i])\n",
    "#         labelsTest.append(i)\n",
    "    #     print(\"Untoken\")\n",
    "    #     print(x)\n",
    "    print(len(dtt))\n",
    "    return dtt\n",
    "dataTest = preproc(dt)\n",
    "print('finish')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import numpy as np\n",
    "dataTest = np.asarray(dataTest)\n",
    "lb = np.asarray(lb)\n",
    "kf = KFold(n_splits=5)\n",
    "kf.get_n_splits(dataTest[0:25000])\n",
    "j=0\n",
    "dataTraining=[]\n",
    "dataTesting=[]\n",
    "labelTraining =[]\n",
    "labelTesting=[]\n",
    "# binTraining=[]\n",
    "# binTesting=[]\n",
    "l1 = np.full((50000), 0); l1[25000:50000] = 1\n",
    "for train_index, test_index in kf.split(dataTest[0:25000]):\n",
    "#     print(\"\\n\\n iterasi keee \",j)\n",
    "#     print(\"\\n TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = dataTest[train_index], dataTest[test_index]\n",
    "    y_train, y_test = lb[train_index], lb[test_index]\n",
    "#     bin_train,bin_test = l1[train_index],l1[test_index]\n",
    "#     print(\"\\n TRAIN:\", train_index+1000, \"TEST:\", test_index+1000, type(X_train))\n",
    "    X_train1, X_test1 = dataTest[train_index+25000], dataTest[test_index+25000]\n",
    "    y_train1, y_test1 = lb[train_index+25000], lb[test_index+25000]\n",
    "#     bin_train1,bin_test1 = l1[train_index+25000],l1[test_index+25000]\n",
    "    \n",
    "    x_tr=np.concatenate((X_train,X_train1))\n",
    "    y_tr=np.concatenate((y_train,y_train1))\n",
    "    x_te = np.concatenate((X_test,X_test1))\n",
    "    y_te = np.concatenate((y_test,y_test1))\n",
    "#     b_tr = np.concatenate((bin_train,bin_train1))\n",
    "#     b_te = np.concatenate((bin_test,bin_test1))\n",
    "#     binTraining.append(b_tr)\n",
    "#     binTesting.append(b_te)\n",
    "    dataTraining.append(x_tr)\n",
    "    labelTraining.append(y_tr)\n",
    "    dataTesting.append(x_te)\n",
    "    labelTesting.append(y_te) \n",
    "    j=j+1\n",
    "\n",
    "print('finish')\n",
    "print(len(dataTesting))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "fiturTraining = []\n",
    "fiturTesting = []\n",
    "for ii in range(5):\n",
    "#     print(ii)\n",
    "#   count vector\n",
    "    count_vect = CountVectorizer(ngram_range=(1,1))\n",
    "    tfidf_transformer = TfidfTransformer()\n",
    "#   tfidf fitur training\n",
    "    X_train_counts = count_vect.fit_transform(dataTraining[ii])\n",
    "    X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "    fiturTraining.append(X_train_tfidf)\n",
    "#   fitur testing\n",
    "    X_new_counts = count_vect.transform(dataTesting[ii])\n",
    "    X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "    fiturTesting.append(X_new_tfidf)\n",
    "print('finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(dataTesting[0][0]))\n",
    "# print(fiturTraining[0].shape)\n",
    "# print(fiturTesting[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm\n",
      "0\n",
      "0\n",
      "pred\n",
      "[[19743   257]\n",
      " [  235 19765]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.99      0.99      0.99     20000\n",
      "         pos       0.99      0.99      0.99     20000\n",
      "\n",
      "    accuracy                           0.99     40000\n",
      "   macro avg       0.99      0.99      0.99     40000\n",
      "weighted avg       0.99      0.99      0.99     40000\n",
      "\n",
      "[[4431  569]\n",
      " [ 779 4221]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.85      0.89      0.87      5000\n",
      "         pos       0.88      0.84      0.86      5000\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n",
      "1\n",
      "1\n",
      "pred\n",
      "[[19776   224]\n",
      " [  203 19797]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.99      0.99      0.99     20000\n",
      "         pos       0.99      0.99      0.99     20000\n",
      "\n",
      "    accuracy                           0.99     40000\n",
      "   macro avg       0.99      0.99      0.99     40000\n",
      "weighted avg       0.99      0.99      0.99     40000\n",
      "\n",
      "[[4193  807]\n",
      " [ 742 4258]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.85      0.84      0.84      5000\n",
      "         pos       0.84      0.85      0.85      5000\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n",
      "\n",
      "2\n",
      "2\n",
      "pred\n",
      "[[19755   245]\n",
      " [  225 19775]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.99      0.99      0.99     20000\n",
      "         pos       0.99      0.99      0.99     20000\n",
      "\n",
      "    accuracy                           0.99     40000\n",
      "   macro avg       0.99      0.99      0.99     40000\n",
      "weighted avg       0.99      0.99      0.99     40000\n",
      "\n",
      "[[4320  680]\n",
      " [ 785 4215]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.85      0.86      0.86      5000\n",
      "         pos       0.86      0.84      0.85      5000\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n",
      "\n",
      "3\n",
      "3\n",
      "pred\n",
      "[[19750   250]\n",
      " [  222 19778]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.99      0.99      0.99     20000\n",
      "         pos       0.99      0.99      0.99     20000\n",
      "\n",
      "    accuracy                           0.99     40000\n",
      "   macro avg       0.99      0.99      0.99     40000\n",
      "weighted avg       0.99      0.99      0.99     40000\n",
      "\n",
      "[[4402  598]\n",
      " [ 813 4187]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.84      0.88      0.86      5000\n",
      "         pos       0.88      0.84      0.86      5000\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "4\n",
      "4\n",
      "pred\n",
      "[[19738   262]\n",
      " [  213 19787]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.99      0.99      0.99     20000\n",
      "         pos       0.99      0.99      0.99     20000\n",
      "\n",
      "    accuracy                           0.99     40000\n",
      "   macro avg       0.99      0.99      0.99     40000\n",
      "weighted avg       0.99      0.99      0.99     40000\n",
      "\n",
      "[[4400  600]\n",
      " [ 884 4116]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.83      0.88      0.86      5000\n",
      "         pos       0.87      0.82      0.85      5000\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "print(\"svm\")\n",
    "for ii in range(5):\n",
    "    print(ii)\n",
    "# classifier\n",
    "    classifier = LinearSVC()\n",
    "    print(ii)\n",
    "    classifier.fit(fiturTraining[ii],labelTraining[ii])\n",
    "    print(\"pred\")\n",
    "    y_pred_tr = classifier.predict(fiturTraining[ii])\n",
    "    print(confusion_matrix(labelTraining[ii], y_pred_tr))\n",
    "    print(classification_report(labelTraining[ii],y_pred_tr))\n",
    "#   new Data\n",
    "    y_pred_te = classifier.predict(fiturTesting[ii])\n",
    "    print(confusion_matrix(labelTesting[ii], y_pred_te))\n",
    "    print(classification_report(labelTesting[ii],y_pred_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16105  3895]\n",
      " [ 3051 16949]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.84      0.81      0.82     20000\n",
      "         pos       0.81      0.85      0.83     20000\n",
      "\n",
      "    accuracy                           0.83     40000\n",
      "   macro avg       0.83      0.83      0.83     40000\n",
      "weighted avg       0.83      0.83      0.83     40000\n",
      "\n",
      "[[3698 1302]\n",
      " [2227 2773]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.62      0.74      0.68      5000\n",
      "         pos       0.68      0.55      0.61      5000\n",
      "\n",
      "    accuracy                           0.65     10000\n",
      "   macro avg       0.65      0.65      0.64     10000\n",
      "weighted avg       0.65      0.65      0.64     10000\n",
      "\n",
      "[[16627  3373]\n",
      " [ 2745 17255]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.86      0.83      0.84     20000\n",
      "         pos       0.84      0.86      0.85     20000\n",
      "\n",
      "    accuracy                           0.85     40000\n",
      "   macro avg       0.85      0.85      0.85     40000\n",
      "weighted avg       0.85      0.85      0.85     40000\n",
      "\n",
      "[[2958 2042]\n",
      " [2154 2846]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.58      0.59      0.59      5000\n",
      "         pos       0.58      0.57      0.58      5000\n",
      "\n",
      "    accuracy                           0.58     10000\n",
      "   macro avg       0.58      0.58      0.58     10000\n",
      "weighted avg       0.58      0.58      0.58     10000\n",
      "\n",
      "[[16304  3696]\n",
      " [ 3361 16639]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.83      0.82      0.82     20000\n",
      "         pos       0.82      0.83      0.83     20000\n",
      "\n",
      "    accuracy                           0.82     40000\n",
      "   macro avg       0.82      0.82      0.82     40000\n",
      "weighted avg       0.82      0.82      0.82     40000\n",
      "\n",
      "[[3408 1592]\n",
      " [2294 2706]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.60      0.68      0.64      5000\n",
      "         pos       0.63      0.54      0.58      5000\n",
      "\n",
      "    accuracy                           0.61     10000\n",
      "   macro avg       0.61      0.61      0.61     10000\n",
      "weighted avg       0.61      0.61      0.61     10000\n",
      "\n",
      "[[16137  3863]\n",
      " [ 3254 16746]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.83      0.81      0.82     20000\n",
      "         pos       0.81      0.84      0.82     20000\n",
      "\n",
      "    accuracy                           0.82     40000\n",
      "   macro avg       0.82      0.82      0.82     40000\n",
      "weighted avg       0.82      0.82      0.82     40000\n",
      "\n",
      "[[3636 1364]\n",
      " [2290 2710]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.61      0.73      0.67      5000\n",
      "         pos       0.67      0.54      0.60      5000\n",
      "\n",
      "    accuracy                           0.63     10000\n",
      "   macro avg       0.64      0.63      0.63     10000\n",
      "weighted avg       0.64      0.63      0.63     10000\n",
      "\n",
      "[[16193  3807]\n",
      " [ 2984 17016]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.84      0.81      0.83     20000\n",
      "         pos       0.82      0.85      0.83     20000\n",
      "\n",
      "    accuracy                           0.83     40000\n",
      "   macro avg       0.83      0.83      0.83     40000\n",
      "weighted avg       0.83      0.83      0.83     40000\n",
      "\n",
      "[[3617 1383]\n",
      " [2219 2781]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.62      0.72      0.67      5000\n",
      "         pos       0.67      0.56      0.61      5000\n",
      "\n",
      "    accuracy                           0.64     10000\n",
      "   macro avg       0.64      0.64      0.64     10000\n",
      "weighted avg       0.64      0.64      0.64     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "for ii in range(5):\n",
    "#     CLASSIFIER\n",
    "    knn = KNeighborsClassifier(n_neighbors=15)\n",
    "    knn.fit(fiturTraining[ii], labelTraining[ii])\n",
    "    y_pred = knn.predict(fiturTraining[ii])\n",
    "    print(confusion_matrix(labelTraining[ii], y_pred))\n",
    "    print(classification_report(labelTraining[ii], y_pred))\n",
    "#   Testing\n",
    "    y_pred_te = knn.predict(fiturTesting[ii])\n",
    "    print(confusion_matrix(labelTesting[ii], y_pred_te))\n",
    "    print(classification_report(labelTesting[ii],y_pred_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[[18746  1254]\n",
      " [ 2375 17625]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.89      0.94      0.91     20000\n",
      "         pos       0.93      0.88      0.91     20000\n",
      "\n",
      "    accuracy                           0.91     40000\n",
      "   macro avg       0.91      0.91      0.91     40000\n",
      "weighted avg       0.91      0.91      0.91     40000\n",
      "\n",
      "[[4427  573]\n",
      " [1081 3919]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.80      0.89      0.84      5000\n",
      "         pos       0.87      0.78      0.83      5000\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.84      0.83      0.83     10000\n",
      "weighted avg       0.84      0.83      0.83     10000\n",
      "\n",
      "1\n",
      "[[18784  1216]\n",
      " [ 2242 17758]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.89      0.94      0.92     20000\n",
      "         pos       0.94      0.89      0.91     20000\n",
      "\n",
      "    accuracy                           0.91     40000\n",
      "   macro avg       0.91      0.91      0.91     40000\n",
      "weighted avg       0.91      0.91      0.91     40000\n",
      "\n",
      "[[4259  741]\n",
      " [ 992 4008]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.81      0.85      0.83      5000\n",
      "         pos       0.84      0.80      0.82      5000\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.83      0.83      0.83     10000\n",
      "weighted avg       0.83      0.83      0.83     10000\n",
      "\n",
      "2\n",
      "[[18772  1228]\n",
      " [ 2342 17658]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.89      0.94      0.91     20000\n",
      "         pos       0.93      0.88      0.91     20000\n",
      "\n",
      "    accuracy                           0.91     40000\n",
      "   macro avg       0.91      0.91      0.91     40000\n",
      "weighted avg       0.91      0.91      0.91     40000\n",
      "\n",
      "[[4342  658]\n",
      " [1001 3999]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.81      0.87      0.84      5000\n",
      "         pos       0.86      0.80      0.83      5000\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.84      0.83      0.83     10000\n",
      "weighted avg       0.84      0.83      0.83     10000\n",
      "\n",
      "3\n",
      "[[18774  1226]\n",
      " [ 2706 17294]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.87      0.94      0.91     20000\n",
      "         pos       0.93      0.86      0.90     20000\n",
      "\n",
      "    accuracy                           0.90     40000\n",
      "   macro avg       0.90      0.90      0.90     40000\n",
      "weighted avg       0.90      0.90      0.90     40000\n",
      "\n",
      "[[4396  604]\n",
      " [1378 3622]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.76      0.88      0.82      5000\n",
      "         pos       0.86      0.72      0.79      5000\n",
      "\n",
      "    accuracy                           0.80     10000\n",
      "   macro avg       0.81      0.80      0.80     10000\n",
      "weighted avg       0.81      0.80      0.80     10000\n",
      "\n",
      "4\n",
      "[[18743  1257]\n",
      " [ 2528 17472]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.88      0.94      0.91     20000\n",
      "         pos       0.93      0.87      0.90     20000\n",
      "\n",
      "    accuracy                           0.91     40000\n",
      "   macro avg       0.91      0.91      0.91     40000\n",
      "weighted avg       0.91      0.91      0.91     40000\n",
      "\n",
      "[[4344  656]\n",
      " [1179 3821]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.79      0.87      0.83      5000\n",
      "         pos       0.85      0.76      0.81      5000\n",
      "\n",
      "    accuracy                           0.82     10000\n",
      "   macro avg       0.82      0.82      0.82     10000\n",
      "weighted avg       0.82      0.82      0.82     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "classifier = BernoulliNB()\n",
    "for ii in range(5):\n",
    "    print(ii)\n",
    "# classifier\n",
    "#     classifier = LinearSVC()\n",
    "    classifier.fit(fiturTraining[ii],labelTraining[ii])\n",
    "    y_pred_tr = classifier.predict(fiturTraining[ii])\n",
    "    print(confusion_matrix(labelTraining[ii], y_pred_tr))\n",
    "    print(classification_report(labelTraining[ii],y_pred_tr))\n",
    "#   new Data\n",
    "    y_pred_te = classifier.predict(fiturTesting[ii])\n",
    "    print(confusion_matrix(labelTesting[ii], y_pred_te))\n",
    "    print(classification_report(labelTesting[ii],y_pred_te))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
